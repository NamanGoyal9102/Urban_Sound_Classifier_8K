{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uq9fI-sX0Juz","executionInfo":{"status":"ok","timestamp":1690904727866,"user_tz":-330,"elapsed":710526,"user":{"displayName":"Naman Goyal","userId":"14901304680611062848"}},"outputId":"8a5aa32a-48c0-48c7-8a02-87ecf1598241"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["('a.tar.gz', <http.client.HTTPMessage at 0x7b08e05b78b0>)"]},"metadata":{},"execution_count":2}],"source":["#DOWNLOADING THE DATA ON THE COLAB'S SERVER\n","import urllib.request\n","urllib.request.urlretrieve (\"https://zenodo.org/record/1203745/files/UrbanSound8K.tar.gz\",\"a.tar.gz\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hf-sDMXW3EdV"},"outputs":[],"source":["import tarfile\n","tar = tarfile.open(\"a.tar.gz\")\n","tar.extractall()\n","tar.close()\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"opd-t_j-4XR9"},"outputs":[],"source":["#forming a panda dataframe from the metadata file\n","data=pd.read_csv(\"UrbanSound8K/metadata/UrbanSound8K.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"ISjNHTqH4aQY"},"outputs":[],"source":["#head of the dataframe\n","data.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"VkbBFd5j4xNQ"},"outputs":[],"source":["#count of datapoints in each of the folders\n","data[\"fold\"].value_counts()"]},{"cell_type":"markdown","source":["# Examples of Data Preprocessing and the Features we will be creating and using\n"],"metadata":{"id":"SgOwCZ9BYy-_"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"ITGpMzzW4z4K"},"outputs":[],"source":["from librosa import display\n","import librosa\n","#feature set\n","#This file is of a dog bark\n","y,sr=librosa.load(\"UrbanSound8K/audio/fold5/100032-3-0-0.wav\")\n","mfccs = librosa.feature.mfcc(y, sr, n_mfcc=36)\n","melspectrogram =librosa.feature.melspectrogram(y=y, sr=sr, n_mels=36,fmax=8000)\n","chroma_stft=librosa.feature.chroma_stft(y=y, sr=sr,n_chroma=36)\n","chroma_cq =librosa.feature.chroma_cqt(y=y, sr=sr,n_chroma=36)\n","chroma_cens =librosa.feature.chroma_cens(y=y, sr=sr,n_chroma=36)\n","melspectrogram.shape,chroma_stft.shape,chroma_cq.shape,chroma_cens.shape,mfccs.shape\n","# TESTING THE DATA PREPROCESSING ON SAMPLE DATASETS TO UNDERSTAND THE PROCESS OF DATA COLLECTION FROM THE DATASET"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"398_bm24BFUa"},"outputs":[],"source":["#MFCC of dog bark\n","import matplotlib.pyplot as plt\n","plt.figure(figsize=(10,4))\n","librosa.display.specshow(mfccs, x_axis='time')\n","plt.colorbar()\n","plt.title('MFCC')\n","plt.tight_layout()"]},{"cell_type":"code","source":["#Melspectrogram of a dog bark\n","plt.figure(figsize=(10,4))\n","librosa.display.specshow(librosa.power_to_db(melspectrogram,ref=np.max),y_axis='mel', fmax=8000,x_axis='time')\n","plt.colorbar(format='%+2.0f dB')\n","plt.title('Mel spectrogram')\n","plt.tight_layout()"],"metadata":{"id":"w_V0an2bYRBA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Chromagram of dog bark\n","plt.figure(figsize=(10,4))\n","librosa.display.specshow(chroma_stft, y_axis='chroma', x_axis='time')\n","plt.colorbar()\n","plt.title('Chromagram')\n","plt.tight_layout()"],"metadata":{"id":"VlGOX0KDYV7U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Chroma cqt of a dog bark\n","plt.figure(figsize=(10,4))\n","librosa.display.specshow(chroma_cq, y_axis='chroma', x_axis='time')\n","plt.colorbar()\n","plt.title('chroma_cqt')\n","plt.tight_layout()"],"metadata":{"id":"1j1MJizhYXBJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Chroma cens of a dog bark\n","plt.figure(figsize=(10,4))\n","librosa.display.specshow(chroma_cens, y_axis='chroma', x_axis='time')\n","plt.colorbar()\n","plt.title('chroma_cens')\n","plt.tight_layout()\n"],"metadata":{"id":"b0PseOyDYZB-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Data Preprocessing and the production of the features for the entire set"],"metadata":{"id":"lNizY76WZEWz"}},{"cell_type":"code","source":["#preprocessing using entire feature set\n","x_data=[ [] for _ in range(10) ]\n","y_label=[ [] for _ in range(10) ]\n","path=\"UrbanSound8K/audio/fold\"\n","for i in tqdm(range(len(data))):\n","    fold_no=str(data.iloc[i][\"fold\"])\n","    file=data.iloc[i][\"slice_file_name\"]\n","    label=data.iloc[i][\"classID\"]\n","    filename=path+fold_no+\"/\"+file\n","    y,sr=librosa.load(filename)\n","    mfccs = np.mean(librosa.feature.mfcc(y, sr, n_mfcc=36).T,axis=0)\n","    melspectrogram = np.mean(librosa.feature.melspectrogram(y=y, sr=sr, n_mels=36,fmax=8000).T,axis=0)\n","    chroma_stft=np.mean(librosa.feature.chroma_stft(y=y, sr=sr,n_chroma=36).T,axis=0)\n","    chroma_cq = np.mean(librosa.feature.chroma_cqt(y=y, sr=sr,n_chroma=36).T,axis=0)\n","    chroma_cens = np.mean(librosa.feature.chroma_cens(y=y, sr=sr,n_chroma=36).T,axis=0)\n","    features=np.reshape(np.vstack((mfccs,melspectrogram,chroma_stft,chroma_cq,chroma_cens)),(36,5))\n","    x_data[int(fold_no)-1].append(features)\n","    y_label[int(fold_no)-1].append(label)\n","    # USED OS TO HAVE THE COMPLETE ADDRESS OF THE FILENAME EACH TIME AND THEN LOADED THAT DATA INTO THE LIBROSA ONE BY ONE UrbanSound8K/audio/fold/fold_no/slice_file_name/class_ID\n","    # loaded these into the librosa and it calculated the mfccs, melspectrogram, chroma_stft, chroma_cq, chroma_cens and then loaded them as features"],"metadata":{"id":"Oit_CJwBYbIU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sum([len(x) for x in x_data])"],"metadata":{"id":"5yvTFCzHYhJe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(data)\n"],"metadata":{"id":"MxTDrBIaYjU1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pickle as pkl\n","\n","with open(\"x_data.pickle\",\"wb\") as f:\n","    pkl.dump(x_data, f)\n","\n","with open(\"y_label.pickle\",\"wb\") as f:\n","    pkl.dump(y_label, f)"],"metadata":{"id":"BQsF-7nxYlWN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Mount Drive"],"metadata":{"id":"Rv43s4-8dZYc"}},{"cell_type":"code","source":["# mount drive with data\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"metadata":{"id":"BvCu5yydYoqC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Fetch Processed Data"],"metadata":{"id":"4OTV3kSYdhq3"}},{"cell_type":"code","source":["#extracting data from pkl files\n","import pickle as pkl\n","\n","with open(\"/content/gdrive/My Drive/UrbanSound8k/x_data.pickle\",\"rb\") as f:\n","  x_data = pkl.load(f)\n","\n","with open(\"/content/gdrive/My Drive/UrbanSound8k/y_label.pickle\",\"rb\") as f:\n","  y_label = pkl.load(f)"],"metadata":{"id":"IMq07GJ6YsL8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#reshape data\n","import numpy as np\n","from keras.utils.np_utils import to_categorical\n","\n","X = []\n","Y = []\n","for i in range(10):\n","  xi = np.array(x_data[i])\n","\n","  #reshaping to shape required by CNN\n","  xi_cnn = np.reshape(xi,(xi.shape[0],xi.shape[1],xi.shape[2], 1))\n","  X.append(xi_cnn)\n","\n","  yi = to_categorical(y_label[i], num_classes=10)\n","  Y.append(yi)\n","  # RESHAPED THE DATA TO MAKE EACH OF THE INTO 10 CLASSES RANDOMLY AND THEN EACH CLASS HAS 873 DATAPOINTS AND ALSO CONVERTED THE Y_CLASS INTO CATEGORIES USINF TO_CATEGORICAL I.E\n","  # BINARY CODED CATRGORY"],"metadata":{"id":"XOICW7XddSkq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"M52ELQmAdTB2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Build Model"],"metadata":{"id":"K0mzYyGYIAkJ"}},{"cell_type":"code","source":["from keras import Sequential\n","from keras.layers import Dense,Conv2D,MaxPooling2D,Flatten,Dropout,Activation\n","from keras.regularizers import l2\n","def get_model():\n","  #forming model\n","  model = Sequential()\n","\n","  #adding layers and forming the model\n","  model.add(Conv2D(64,kernel_size=5,strides=1,padding=\"Same\",activation=\"relu\",input_shape=(36,5,1)))\n","  model.add(MaxPooling2D(padding=\"same\"))\n","\n","  model.add(Conv2D(128,kernel_size=5,strides=1,padding=\"same\",activation=\"relu\"))\n","  model.add(MaxPooling2D(padding=\"same\"))\n","  model.add(Dropout(0.3))\n","\n","  model.add(Flatten())\n","\n","  model.add(Dense(512,activation=\"relu\"))\n","  model.add(Dropout(0.4))\n","\n","  model.add(Dense(512,activation=\"relu\"))\n","  model.add(Dropout(0.4))\n","\n","  model.add(Dense(10,activation=\"softmax\"))\n","\n","  #compiling\n","  model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n","\n","  return model\n","  # BUILT THE MODEL USING 2 CONVULATIONAL LA"],"metadata":{"id":"bUwly20LdTMd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 10 Cross Validation"],"metadata":{"id":"ipMhu2s7IvAN"}},{"cell_type":"code","source":["sum_train_loss = 0\n","sum_test_loss = 0\n","sum_train_acc = 0\n","sum_test_acc = 0\n","\n","for i in range(10):\n","  model = get_model()\n","\n","  x_train = np.concatenate([X[j] for j in [k for k in range(10) if k not in [i]]])\n","  y_train = np.concatenate([Y[j] for j in [k for k in range(10) if k not in [i]]])\n","\n","  x_test = X[i]\n","  y_test = Y[i]\n","\n","  model.fit(x_train, y_train, epochs=30, batch_size=50)\n","\n","  #train and test loss and scores respectively\n","  train_eval = model.evaluate(x_train, y_train)\n","  test_eval = model.evaluate(x_test, y_test)\n","\n","  print(\"Results for folder: \", i)\n","  print(train_eval)\n","  print(test_eval)\n","\n","  sum_train_loss += train_eval[0]\n","  sum_test_loss += test_eval[0]\n","  sum_train_acc += train_eval[1]\n","  sum_test_acc += test_eval[1]"],"metadata":{"id":"UrjaE4iPdTTl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Result"],"metadata":{"id":"Nk3qlU3vJDK8"}},{"cell_type":"code","source":["#train and test scores\n","print(\"Avg Train Loss: \", sum_train_loss/10)\n","print(\"Avg Train Acc: \", sum_train_acc/10)\n","print(\"Avg Test Loss Score: \", sum_test_loss/10)\n","print(\"Avg Test Loss Acc: \", sum_test_acc/10)"],"metadata":{"id":"Cffb_kixdTdQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Avg Train Loss:  0.10445725694298744\n","Avg Train Acc:  0.969599062204361\n","Avg Test Loss Score:  1.6439483225345612\n","Avg Test Loss Acc:  0.6261717498302459"],"metadata":{"id":"2FwXHID_dTkk"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNgBBL4/PgC8XzxxH4v3zVc"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}